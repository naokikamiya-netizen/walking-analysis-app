# ==========================================================
#  app.py - æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª (v1.7_no_rotate_fix2)
# ==========================================================
import streamlit as st
from scipy.signal import find_peaks
import cv2
import mediapipe as mp
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import tempfile
import japanize_matplotlib  # æ—¥æœ¬èªè¡¨ç¤ºã®ãŸã‚

def analyze_walking(video_path, progress_bar, status_text):
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1,
                        min_detection_confidence=0.5, min_tracking_confidence=0.5)
    mp_drawing = mp.solutions.drawing_utils

    status_text.text("ã‚¹ãƒ†ãƒƒãƒ—1/2: åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error("ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None, None

    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    all_angles, all_landmarks = [], []

    orientation_locked = False
    is_flipped = False

    for frame_count in range(total_frames):
        success, image = cap.read()
        if not success:
            break

        progress_bar.progress((frame_count + 1) / total_frames * 0.5)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        all_landmarks.append(results.pose_landmarks)

        current_angle = 0
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            try:
                p_ls = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]
                p_rs = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]
                if p_ls.visibility > 0.5 and p_rs.visibility > 0.5:
                    delta_y = (p_rs.y - p_ls.y) * frame_h
                    delta_x = (p_rs.x - p_ls.x) * frame_w
                    angle = math.degrees(math.atan2(delta_y, delta_x))
                    if angle > 90: angle -= 180
                    elif angle < -90: angle += 180
                    if abs(angle) < 80: current_angle = -angle
            except Exception:
                pass
        all_angles.append(current_angle)

    cap.release()
    pose.close()

    if len(all_angles) < int(fps):
        return None, None

    # ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ï¼‹å¹³æ»‘åŒ–
    filtered = [all_angles[0]]
    for i in range(1, len(all_angles)):
        if abs(all_angles[i] - filtered[-1]) > 10:
            filtered.append(filtered[-1])
        else:
            filtered.append(all_angles[i])
    smoothed = pd.Series(filtered).rolling(window=11, min_periods=1, center=True).mean().tolist()

    angles_np = np.array(smoothed)
    num_static_frames = min(int(fps * 1.0), 30)
    static_tilt = np.mean(angles_np[:num_static_frames])
    dynamic = angles_np[num_static_frames:]
    left_down = dynamic[dynamic > 0]
    right_down = dynamic[dynamic < 0]
    summary = {
        "static_tilt": static_tilt,
        "avg_left_down_dynamic": np.mean(left_down) if len(left_down) > 0 else 0,
        "avg_right_down_dynamic": np.mean(right_down) if len(right_down) > 0 else 0
    }

    # === çµæœãƒ“ãƒ‡ã‚ª ===
    status_text.text("ã‚¹ãƒ†ãƒƒãƒ—2/2: çµæœã®ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆä¸­...")
    cap = cv2.VideoCapture(video_path)
    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))

    right_panel_w = int(frame_w * 0.7)
    final_w, final_h = frame_w + right_panel_w, frame_h

    temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    out = cv2.VideoWriter(temp_output.name, cv2.VideoWriter_fourcc(*'mp4v'),
                          fps, (final_w, final_h))

    time_stamps = np.arange(len(angles_np)) / fps
    y_limit = 15.0
    summary_h = int(final_h * 0.45)

    # Summaryãƒ‘ãƒãƒ«ç”»åƒä½œæˆ
    fig_s, ax_s = plt.subplots(figsize=(right_panel_w/100, summary_h/100), dpi=100, facecolor='#1E1E1E')
    ax_s.axis('off')
    static_label = "é™çš„å‚¾æ–œ (ç«‹ä½):"
    static_value_text = f"{abs(summary['static_tilt']):.2f} åº¦ ({'å³' if summary['static_tilt'] < 0 else 'å·¦'}è‚©ä¸‹ãŒã‚Š)"
    ax_s.text(0.5, 0.85, static_label, color='white', fontsize=20, ha='center', va='center', weight='bold')
    ax_s.text(0.5, 0.65, static_value_text, color='#FFC300', fontsize=28, ha='center', va='center', weight='bold')
    ax_s.text(0.1, 0.35, "å‹•çš„å‚¾æ–œ (å·¦):", color='#33FF57', fontsize=20, ha='left', va='center', weight='bold')
    ax_s.text(0.9, 0.35, f"{summary['avg_left_down_dynamic']:.2f} åº¦", color='#33FF57', fontsize=28, ha='right', va='center', weight='bold')
    ax_s.text(0.1, 0.1, "å‹•çš„å‚¾æ–œ (å³):", color='#33A8FF', fontsize=20, ha='left', va='center', weight='bold')
    ax_s.text(0.9, 0.1, f"{abs(summary['avg_right_down_dynamic']):.2f} åº¦", color='#33A8FF', fontsize=28, ha='right', va='center', weight='bold')
    fig_s.tight_layout(pad=0)
    fig_s.canvas.draw()
    summary_img = cv2.cvtColor(np.asarray(fig_s.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR)
    plt.close(fig_s)

    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    for i in range(total_frames):
        success, image = cap.read()
        if not success:
            break
        progress_bar.progress(0.5 + (i + 1) / total_frames * 0.5)

        if i < len(all_landmarks) and all_landmarks[i]:
            mp_drawing.draw_landmarks(
                image, all_landmarks[i], mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),
                connection_drawing_spec=mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)
            )

        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        fig_g, ax_g = plt.subplots(figsize=(right_panel_w/100, (final_h - summary_h)/100), dpi=100)
        fig_g.set_facecolor('#1E1E1E')
        ax_g.set_facecolor('#1E1E1E')
        ax_g.tick_params(colors='white', labelsize=10)
        [s.set_edgecolor('white') for s in ax_g.spines.values()]
        ax_g.plot(time_stamps, angles_np, color='#00FFFF', lw=2)
        if i < len(time_stamps):
            ax_g.plot(time_stamps[i], angles_np[i], 'o', markersize=8, color='#FF1493')
        ax_g.axhline(0, color='red', linestyle='--', lw=1)
        ax_g.set_ylim(-y_limit, y_limit)
        ax_g.set_xlabel('æ™‚é–“(ç§’)', color='white', fontsize=12)
        ax_g.set_ylabel('è§’åº¦(åº¦)', color='white', fontsize=12)
        fig_g.tight_layout(pad=1.5)
        fig_g.canvas.draw()
        graph_img = cv2.cvtColor(np.asarray(fig_g.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR)
        plt.close(fig_g)

        # ã‚µã‚¤ã‚ºæƒãˆ
        graph_img = cv2.resize(graph_img, (right_panel_w, final_h - summary_h))
        summary_img_resized = cv2.resize(summary_img, (right_panel_w, summary_h))
        right_panel = cv2.vconcat([graph_img, summary_img_resized])
        final_frame = cv2.hconcat([image, right_panel])
        out.write(final_frame)

    out.release()
    cap.release()
    status_text.text("å®Œäº†ï¼")
    return temp_output.name, summary
# ==========================================================
# Streamlit UIï¼ˆã‚¢ãƒ—ãƒªã®è¡¨ç¤ºéƒ¨åˆ†ï¼‰
# ==========================================================
st.set_page_config(page_title="æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒªï¼ˆå›è»¢ãªã—verï¼‰")

uploaded_file = st.file_uploader("æ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["mp4", "mov", "avi"])

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_path = tmp_file.name

    progress_bar = st.progress(0)
    status_text = st.empty()

    output_path, summary = analyze_walking(tmp_path, progress_bar, status_text)

    if output_path:
        st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼çµæœã‚’å†ç”Ÿã§ãã¾ã™ğŸ‘‡")
        st.video(output_path)
        st.write("### çµæœã‚µãƒãƒªãƒ¼")
        st.json(summary)
    else:
        st.error("å‹•ç”»ã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚åˆ¥ã®å‹•ç”»ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
